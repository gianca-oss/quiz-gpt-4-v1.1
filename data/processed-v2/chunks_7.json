[
  {
    "id": "p468_c0",
    "page": 468,
    "text": "EVOLUTIONARY COMPUTATION 49 EVOLUTIONARY ALGORITHM A stochastic population-based metaheuristic that uses some mechanisms inspired by biological evolution: • Reproduction • Inheritance • Mutation • Selection REQUIREMENTS – (a lot of) simulations → natural evolution works over millions of generations!",
    "start": 0,
    "end": 301,
    "length": 301,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.5,
      "keywords": [
        "evolutionary",
        "evolution",
        "computation",
        "algorithm",
        "stochastic",
        "population",
        "based",
        "metaheuristic",
        "that",
        "uses"
      ]
    }
  },
  {
    "id": "p469_c0",
    "page": 469,
    "text": "EVOLUTIONARY COMPUTATION 50 THE KEY ELEMENTS: INDIVIDUAL & FITNESS An individual encodes a potential solution for a given problem, e. g. : – A list of real numbers – A sequence of cities – A bit string – Etc. Each individual has a fi tness , that is a metric of how good that solution is for a speci fi c problem. 10011010100 NOTE : mixed representations are also possible! E. g. a part of the genotype is binary, another real-valued, etc.",
    "start": 0,
    "end": 440,
    "length": 440,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 2.195,
      "keywords": [
        "individual",
        "solution",
        "problem",
        "real",
        "that",
        "evolutionary",
        "computation",
        "elements",
        "fitness",
        "encodes"
      ]
    }
  },
  {
    "id": "p470_c0",
    "page": 470,
    "text": "EVOLUTIONARY COMPUTATION 51 DISCRETE REPRESENTATIONS The genotype is a sequence (or an array of sequences) of n discrete symbols drawn from alphabet with cardinality k. E. g. , a binary string of 8 digits ( n =8, k =2), such as 01010100, can be mapped into different phenotypes, depending on the optimization problem (just to give some examples): 3. A binary assignment, such as a job schedule problem • job=gene position • time=gene value 2. To real value r in range [ min , max ]: r = min + ( i /255)( max - min ) 1.",
    "start": 0,
    "end": 519,
    "length": 519,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": true,
      "hasList": false,
      "hasExample": false,
      "importance": 17.59,
      "keywords": [
        "discrete",
        "binary",
        "such",
        "problem",
        "gene",
        "value",
        "evolutionary",
        "computation",
        "representations",
        "genotype"
      ]
    }
  },
  {
    "id": "p471_c0",
    "page": 471,
    "text": "EVOLUTIONARY COMPUTATION 52 SEQUENCE REPRESENTATIONS It is a particular case of discrete representation used e. g. for Traveling Salesman Problems (TSP), i. e. , plan a path to visit n cities under some constraints, and problems alike. In this case the individual is a permutation of n different symbols (e. g. integers, letters, or labels), each of which occurs exactly once. E. g.",
    "start": 0,
    "end": 383,
    "length": 383,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.91,
      "keywords": [
        "case",
        "problems",
        "evolutionary",
        "computation",
        "sequence",
        "representations",
        "particular",
        "discrete",
        "representation",
        "used"
      ]
    }
  },
  {
    "id": "p472_c0",
    "page": 472,
    "text": "EVOLUTIONARY COMPUTATION 53 REAL-VALUED REPRESENTATIONS The genotype is a sequence of real values that represent the problem parameters. • Used when high-precision parameter optimization is required • For example, genetic encoding of wing pro fi le for shape optimization: Evolvable wing made of deformable material with pressure tubes. In this case the genotype is a vector representing the pressure values of 14 tubes.",
    "start": 0,
    "end": 421,
    "length": 421,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": true,
      "importance": 2.1,
      "keywords": [
        "real",
        "genotype",
        "values",
        "optimization",
        "wing",
        "pressure",
        "tubes",
        "evolutionary",
        "computation",
        "valued"
      ]
    }
  },
  {
    "id": "p473_c0",
    "page": 473,
    "text": "EVOLUTIONARY COMPUTATION 54 population evaluation of fi tness parents selection offspring (new individuals) replacement reproduction (genetic operators) CENSORED A GENERIC EVOLUTIONARY ALGORITHM FLOW",
    "start": 0,
    "end": 200,
    "length": 200,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.995,
      "keywords": [
        "evolutionary",
        "computation",
        "population",
        "evaluation",
        "tness",
        "parents",
        "selection",
        "offspring",
        "individuals",
        "replacement"
      ]
    }
  },
  {
    "id": "p474_c0",
    "page": 474,
    "text": "EVOLUTIONARY COMPUTATION 55 INITIAL POPULATION Should be suf fi ciently large to cover the search space (! ), but suf fi ciently small in terms of evaluations (typical size: between 10s and 1000s individuals). Uniform sample of search space: • Binary strings: 0 or 1 with probability 0. 5 (similarly for other discrete representations) • Real-valued representations: uniform on a given interval if bounded phenotype (e. g. , +2. 0, -2. 0), otherwise “best guess” (based on domain knowledge). Alternatively, use a DoE (Design of Experiments) algorithm. • Trees are built recursively starting from root: root is randomly chosen from Function set; for every branch, randomly choose among all elements of Function set and of Terminal set; if terminal is chosen, it becomes leaf. A maximum tree depth must be chosen. IMPORTANT : hand-designed genotypes may cause a loss of genetic diversity and/or an unrecoverable bias in the evolutionary process!",
    "start": 0,
    "end": 944,
    "length": 944,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": true,
      "importance": 9.715,
      "keywords": [
        "chosen",
        "evolutionary",
        "ciently",
        "search",
        "space",
        "uniform",
        "representations",
        "from",
        "root",
        "randomly"
      ]
    }
  },
  {
    "id": "p475_c0",
    "page": 475,
    "text": "EVOLUTIONARY COMPUTATION 56 population evaluation of fi tness parents selection offspring (new individuals) replacement reproduction (genetic operators) CENSORED A GENERIC EVOLUTIONARY ALGORITHM FLOW",
    "start": 0,
    "end": 200,
    "length": 200,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.995,
      "keywords": [
        "evolutionary",
        "computation",
        "population",
        "evaluation",
        "tness",
        "parents",
        "selection",
        "offspring",
        "individuals",
        "replacement"
      ]
    }
  },
  {
    "id": "p476_c0",
    "page": 476,
    "text": "EVOLUTIONARY COMPUTATION 57 FITNESS FUNCTION = OBJECTIVE FUNCTION Evaluates the performance of a phenotype with (one or more) numerical scores. • Choice of components; e. g. , lift and drag of a wing • Combination of components; e. g. (lift + 1. 0/drag) or (lift - drag) • Extensive test of each phenotype (with noise, repeated evaluations are needed) • The more the fi tness function can discriminate (return different values), the better • Warning! “You Get What You Evaluate” AN INTERESTING CONCEPT Subjective fi tness : select phenotype by human inspection (basis of IEC, Interactive Evolution Computation) • Used when aesthetic properties cannot be quanti fi ed objectively (e. g. visual art, music, design, etc. ) • Can be combined with an objective fi tness function • E. g. , Picbreeder http://picbreeder.",
    "start": 0,
    "end": 814,
    "length": 814,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": true,
      "hasList": false,
      "hasExample": true,
      "importance": 19.065,
      "keywords": [
        "function",
        "phenotype",
        "with",
        "lift",
        "drag",
        "tness",
        "computation",
        "objective",
        "more",
        "components"
      ]
    }
  },
  {
    "id": "p477_c0",
    "page": 477,
    "text": "EVOLUTIONARY COMPUTATION 58 population evaluation of fi tness parents selection offspring (new individuals) replacement reproduction (genetic operators) CENSORED A GENERIC EVOLUTIONARY ALGORITHM FLOW",
    "start": 0,
    "end": 200,
    "length": 200,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.995,
      "keywords": [
        "evolutionary",
        "computation",
        "population",
        "evaluation",
        "tness",
        "parents",
        "selection",
        "offspring",
        "individuals",
        "replacement"
      ]
    }
  },
  {
    "id": "p478_c0",
    "page": 478,
    "text": "EVOLUTIONARY COMPUTATION 59 FITNESS-PROPORTIONATE SELECTION (ROULETTE-WHEEL SELECTION) The probability that an individual makes an offspring is proportional to how good its fi tness is with respect to the population fi tness: p ( i ) = f ( i )/ Σ f ( i ), i is the individual index → Biases selection towards the most- fi t individuals!",
    "start": 0,
    "end": 337,
    "length": 337,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.68,
      "keywords": [
        "selection",
        "individual",
        "tness",
        "evolutionary",
        "computation",
        "fitness",
        "proportionate",
        "roulette",
        "wheel",
        "probability"
      ]
    }
  },
  {
    "id": "p479_c0",
    "page": 479,
    "text": "EVOLUTIONARY COMPUTATION 60 TOURNAMENT SELECTION For every offspring to be generated: 1. Pick randomly k individuals from the population, where k is the tournament size < N, N being the population size (larger k = larger selection pressure, i. e. , individual have a higher chance to compete against individuals with higher fi tness) 2. Choose the individual with the highest fi tness and make a copy 3.",
    "start": 0,
    "end": 404,
    "length": 404,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": true,
      "hasList": false,
      "hasExample": false,
      "importance": 17.015,
      "keywords": [
        "tournament",
        "selection",
        "individuals",
        "population",
        "size",
        "larger",
        "individual",
        "higher",
        "with",
        "tness"
      ]
    }
  },
  {
    "id": "p480_c0",
    "page": 480,
    "text": "EVOLUTIONARY COMPUTATION 61 population evaluation of fi tness parents selection offspring (new individuals) replacement reproduction (genetic operators) CENSORED A GENERIC EVOLUTIONARY ALGORITHM FLOW",
    "start": 0,
    "end": 200,
    "length": 200,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.995,
      "keywords": [
        "evolutionary",
        "computation",
        "population",
        "evaluation",
        "tness",
        "parents",
        "selection",
        "offspring",
        "individuals",
        "replacement"
      ]
    }
  },
  {
    "id": "p481_c0",
    "page": 481,
    "text": "EVOLUTIONARY COMPUTATION 62 RECOMBINATION (CROSSOVER) • Emulates recombination of genetic material from two parents during meiosis • Exploitation of synergy of sub-solutions (building blocks) from parents • Applied to randomly paired offspring with a given probability Pc One point Uniform Arithmetic For sequences For trees",
    "start": 0,
    "end": 325,
    "length": 325,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.62,
      "keywords": [
        "recombination",
        "from",
        "parents",
        "evolutionary",
        "computation",
        "crossover",
        "emulates",
        "genetic",
        "material",
        "during"
      ]
    }
  },
  {
    "id": "p482_c0",
    "page": 482,
    "text": "EVOLUTIONARY COMPUTATION 63 MUTATION • Emulates genetic mutations • Exploration of variation of existing solutions • Applied to each gene in the genotype with a given probability Pm For trees Binary genotypes Sequence genotypes Real-valued genotypes",
    "start": 0,
    "end": 250,
    "length": 250,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.245,
      "keywords": [
        "genotypes",
        "evolutionary",
        "computation",
        "mutation",
        "emulates",
        "genetic",
        "mutations",
        "exploration",
        "variation",
        "existing"
      ]
    }
  },
  {
    "id": "p483_c0",
    "page": 483,
    "text": "EVOLUTIONARY COMPUTATION 64 population evaluation of fi tness parents selection offspring (new individuals) replacement reproduction (genetic operators) CENSORED A GENERIC EVOLUTIONARY ALGORITHM FLOW",
    "start": 0,
    "end": 200,
    "length": 200,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.995,
      "keywords": [
        "evolutionary",
        "computation",
        "population",
        "evaluation",
        "tness",
        "parents",
        "selection",
        "offspring",
        "individuals",
        "replacement"
      ]
    }
  },
  {
    "id": "p484_c0",
    "page": 484,
    "text": "EVOLUTIONARY COMPUTATION 65 REPLACEMENT (OR “SURVIVOR SELECTION”) • Generational replacement : old population is entirely replaced by offspring (also called “aged-based” replacement, or “non-overlapping” replacement, most frequent method) • Generational rollover : insert offspring “in place”, i. e. , replace worse individuals in the current generation. A special case is the Steady-State scheme (Whitley et al. , 1988): one offspring is generated per generation, one member of the population (the worst one) is replaced.",
    "start": 0,
    "end": 523,
    "length": 523,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 7.609999999999999,
      "keywords": [
        "replacement",
        "offspring",
        "generational",
        "population",
        "replaced",
        "generation",
        "1988",
        "evolutionary",
        "computation",
        "survivor"
      ]
    }
  },
  {
    "id": "p485_c0",
    "page": 485,
    "text": "EVOLUTIONARY COMPUTATION 66 DATA ANALYSIS: MONITORING PERFORMANCE • Track best/worst and/or population average fi tness (+/- std. dev. ) of each generation • Multiple runs are necessary plot average data and standard error (“anytime behavior”) • Fitness graphs (also called “ fi tness trends”) are meaningful only if the problem is stationary, i. e. , the fi tness function does not change over time • These plots can be used to detect if the algorithm stagnated or (prematurely) converged Stagnation : no further evolution possible even if the population remains diverse (individuals are far from each other, but new individuals are worse). Premature convergence : no further evolution possible since the population lost diversity (individuals are too close to each other.",
    "start": 0,
    "end": 774,
    "length": 774,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.865,
      "keywords": [
        "population",
        "tness",
        "each",
        "individuals",
        "data",
        "average",
        "further",
        "evolution",
        "possible",
        "other"
      ]
    }
  },
  {
    "id": "p486_c0",
    "page": 486,
    "text": "EVOLUTIONARY COMPUTATION 67 WHY EVOLUTIONARY ALGORITHMS WORK • Classic optimization algorithms (“local search” methods) work on a single solution at a time, perturbed according to some logics • They can be very good at exploitation (fast convergence to local optimum close to the starting point), but not at exploration (they may miss the global optimum) • They are not parallelizable single-solution algorithms: like a single “hill-climber",
    "start": 0,
    "end": 441,
    "length": 441,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 2.2,
      "keywords": [
        "algorithms",
        "single",
        "they",
        "evolutionary",
        "work",
        "local",
        "solution",
        "optimum",
        "computation",
        "classic"
      ]
    }
  },
  {
    "id": "p487_c0",
    "page": 487,
    "text": "EVOLUTIONARY COMPUTATION 68 population-based algorithms: multiple, parallel hill-climbers variable step-sizes WHY EVOLUTIONARY ALGORITHMS WORK • They are inherently parallel(izable) • They are both good at exploitation AND exploration • Each solution may be perturbed differently (different search perspectives/search strategies) • Interactions (i. e. , exchange of information, e. g.",
    "start": 0,
    "end": 385,
    "length": 385,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.92,
      "keywords": [
        "evolutionary",
        "algorithms",
        "parallel",
        "they",
        "search",
        "computation",
        "population",
        "based",
        "multiple",
        "hill"
      ]
    }
  },
  {
    "id": "p488_c0",
    "page": 488,
    "text": "EVOLUTIONARY COMPUTATION 69 SOME APPLICATIONS • Parameters optimization • Finance/portfolio optimization • Model & neural network training • Forecast • Scheduling • Telecom/Networking • CAD/CAE problems • Database/Data mining • Bioinformatics • Bug identi fi cation • Art (music, design, websites, etc.",
    "start": 0,
    "end": 303,
    "length": 303,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.51,
      "keywords": [
        "optimization",
        "evolutionary",
        "computation",
        "some",
        "applications",
        "parameters",
        "finance",
        "portfolio",
        "model",
        "neural"
      ]
    }
  },
  {
    "id": "p490_c0",
    "page": 490,
    "text": "SWARM INTELLIGENCE 71 WHAT IS SWARM INTELLIGENCE? Some “social” animals live and operate in groups. When these animals perform some tasks together can make things that wouldn’t be able to do when they are alone (showing a form of collective intelligence , as opposed to individual intelligence). E. g. : foraging, defending from predators, building complex structures, etc. Swarm : a group of “simple” agents (not necessarily animals) that communicate with each other (either directly or indirectly), by changing their own state or acting on their local environment. Swarm Intelligence : the property of a system whereby the collective behaviors of “simple” agents interacting locally cause coherent functional global patterns to emerge ( emergent behavior ).",
    "start": 0,
    "end": 760,
    "length": 760,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.795,
      "keywords": [
        "intelligence",
        "swarm",
        "animals",
        "some",
        "when",
        "that",
        "collective",
        "simple",
        "agents",
        "their"
      ]
    }
  },
  {
    "id": "p491_c0",
    "page": 491,
    "text": "COMPUTATIONAL SWARM INTELLIGENCE 72 ANT COLONY OPTIMIZATION • Mimics the navigation strategy used by foraging ants (Dorigo et al.",
    "start": 0,
    "end": 130,
    "length": 130,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.645,
      "keywords": [
        "computational",
        "swarm",
        "intelligence",
        "colony",
        "optimization",
        "mimics",
        "navigation",
        "strategy",
        "used",
        "foraging"
      ]
    }
  },
  {
    "id": "p492_c0",
    "page": 492,
    "text": "COMPUTATIONAL SWARM INTELLIGENCE 73 ANT COLONY OPTIMIZATION • Notes on algorithmic performance - Finds best solution on “small” problems (e. g. TSP of up to 30 cities) - Finds good solutions on large problems compared to other techniques - Finds best solution on large problems when coupled with other search techniques - Can operate on dynamic problems (e. g. , node malfunctioning) that require fast rerouting (ant trails are adaptive!",
    "start": 0,
    "end": 438,
    "length": 438,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 2.185,
      "keywords": [
        "problems",
        "finds",
        "best",
        "solution",
        "large",
        "other",
        "techniques",
        "computational",
        "swarm",
        "intelligence"
      ]
    }
  },
  {
    "id": "p494_c0",
    "page": 494,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 75 MULTI-OBJECTIVE OPTIMIZATION PROBLEMS (MOPS) A wide range of problems (virtually all real-world problems) are characterized by the presence of a number of n possibly con fl icting objectives, e. g. : • buying a car: comfort vs price • buying a house: location vs size vs quality vs price • choosing a job: location vs salary vs fl exibility vs duration of the contract • engineering design: lightness vs strength For instance, when we buy a car, we would like the car to be as cheap as possible (minimize cost) and as comfortable as possible (maximize comfort). If we consider the two objectives separately , we’ll probably obtain two different optimal solutions. BUT, neither of them is likely what we want... ?",
    "start": 0,
    "end": 745,
    "length": 745,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.72,
      "keywords": [
        "problems",
        "multi",
        "objective",
        "optimization",
        "objectives",
        "buying",
        "comfort",
        "price",
        "location",
        "possible"
      ]
    }
  },
  {
    "id": "p495_c0",
    "page": 495,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 76 MULTI-OBJECTIVE OPTIMIZATION PROBLEMS (MOPS) Car Price Comfort A 15k 4 B 20k 6 C 25k 7 D 30k 6 E 30k 8 F 40k 8 1 2 3 4 5 6 7 9 8 15k 20k 25k 30k 35k 40k 45k Price Comfort ... what if there was a car with cost 15k and comfort 9?",
    "start": 0,
    "end": 260,
    "length": 260,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.295,
      "keywords": [
        "comfort",
        "multi",
        "objective",
        "optimization",
        "price",
        "problems",
        "mops",
        "what",
        "there",
        "with"
      ]
    }
  },
  {
    "id": "p496_c0",
    "page": 496,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 77 CONVENTIONAL APPROACHES (“A PRIORI” METHODS) Characterized by the fact that some decisions must be made a priori, i. e. before optimization , in order to solve the MOP as (one or more) single-objective problems. 1. Scalarization : different objectives are combined into one (non-)linear function. E. g. (for two objectives f 1 and f 2 ): f = α × f 1 -(1- α ) × f 2 f =( f 1 +1. 0/ f 2 ) f = f 1 α × f 2 (1- α ) ... The most common scalarization function is a weighted sum of the objectives : f= w 1 × f 1 + w 2 × f 2 +... Important to take into account : - how each objective increases/decreases when f is minimized or maximized - different orders of magnitudes for each objective → magnitude of weights is crucial! - different weights correspond to different rankings (importance) of the objectives - this approach corresponds to an a priori restriction of the fi tness space , i. e.",
    "start": 0,
    "end": 917,
    "length": 917,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": true,
      "hasList": false,
      "hasExample": false,
      "importance": 19.58,
      "keywords": [
        "objective",
        "different",
        "objectives",
        "priori",
        "optimization",
        "scalarization",
        "into",
        "function",
        "each",
        "weights"
      ]
    }
  },
  {
    "id": "p497_c0",
    "page": 497,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 78 Vilfredo Pareto, Manual of Political Economy , 1896 CONVENTIONAL APPROACHES (“A PRIORI” METHODS) 2. Lexicographic ordering : the objectives < f 1 , f 2 , ... f k > are ranked in a user-de fi ned order of importance , so that f 1 is the most important and f k is the least important. Then a sequence of single-objective optimization problems is solved, where fi rst f 1 is optimized (ignoring f 2 , ... f k ) to get an optimum f 1 * , then f 2 is optimized imposing a constraint f 1 ≤ f 1 * (in case of maximization), then f 3 is optimized with constraints f 1 ≤ f 1 * and f 2 ≤ f 2 * , and so on so forth. 3. ε -constraint method : k single-objective optimization problems are solved separately, one for each objective, imposing for each problem k -1 constraints corresponding to the other k -1 problems, i. e. f j ≤ ε j where ε j are user-de fi ned thresholds. Some questions to ask: 1) How should the single objectives be ranked? 2) What is the effect of ranking on the resulting trade-off? 3) Is it possible to consider all the objectives simultaneously ?",
    "start": 0,
    "end": 1091,
    "length": 1091,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 10.45,
      "keywords": [
        "objective",
        "optimization",
        "objectives",
        "then",
        "single",
        "problems",
        "optimized",
        "ranked",
        "user",
        "important"
      ]
    }
  },
  {
    "id": "p498_c0",
    "page": 498,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 79 MULTI-OBJECTIVE OPTIMIZATION PROBLEMS (MOPS) SCALARIZATION (MAXIMIZATION) f=(40k-price) + 10k × comfort 25k + 40k = 65k 20k + 60k = 80k 15k + 70k = 85k 10k + 60k = 80k 10k + 80k = 90k Optimum: E 0 + 80k = 80k f=(40k-price) + 1k × comfort 25k + 4k = 29k Optimum: A 20k + 6k = 26k 15k + 7k = 22k 10k + 6k = 16k 10k + 8k = 18k 0 + 8k = 8k Car Price Comfort A 15k 4 B 20k 6 C 25k 7 D 30k 6 E 30k 8 F 40k 8",
    "start": 0,
    "end": 434,
    "length": 434,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": true,
      "hasList": false,
      "hasExample": false,
      "importance": 12.165,
      "keywords": [
        "price",
        "comfort",
        "multi",
        "objective",
        "optimization",
        "optimum",
        "problems",
        "mops",
        "scalarization",
        "maximization"
      ]
    }
  },
  {
    "id": "p499_c0",
    "page": 499,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 80 MULTI-OBJECTIVE OPTIMIZATION PROBLEMS (MOPS) LEXICOGRAPHIC ORDERING Price more important than comfort 1. Minimize price: {A} 2. Maximize comfort in {A}: A Optimum: A Comfort more important than price 1. Maximize comfort: {E, F} 2. Minimize price in {E, F}: E Optimum: E ε -CONSTRAINT METHOD - Minimize price (s. t. comfort ≥ 7): { C , E, F} - Maximize comfort (s. t.",
    "start": 0,
    "end": 399,
    "length": 399,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 6.99,
      "keywords": [
        "comfort",
        "price",
        "minimize",
        "maximize",
        "multi",
        "objective",
        "optimization",
        "more",
        "important",
        "than"
      ]
    }
  },
  {
    "id": "p500_c0",
    "page": 500,
    "text": "500 1000 1500 2000 2500 3000 3500 cost water supply 5 10 15 20 MULTI-OBJECTIVE OPTIMIZATION 81 PARETO-DOMINANCE Given a certain solution, we can identify solutions that are certainly better (worse) than it, i. e. they are better (worse) for all objectives, or solutions that are “incomparable”, i. e. they are better w. r. t. at least one objective, but worse w. r. t. to the others.",
    "start": 0,
    "end": 384,
    "length": 384,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.915,
      "keywords": [
        "better",
        "worse",
        "objective",
        "solutions",
        "that",
        "they",
        "1000",
        "1500",
        "2000",
        "2500"
      ]
    }
  },
  {
    "id": "p501_c0",
    "page": 501,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 82 PARETO-DOMINANCE De fi nition : A solution i is said to “Pareto-dominate” a solution j if (both conditions must hold!",
    "start": 0,
    "end": 150,
    "length": 150,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.745,
      "keywords": [
        "pareto",
        "solution",
        "multi",
        "objective",
        "optimization",
        "dominance",
        "nition",
        "said",
        "dominate",
        "both"
      ]
    }
  },
  {
    "id": "p502_c0",
    "page": 502,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 83 better better 500 1000 1500 2000 2500 3000 3500 cost water supply 5 10 15 20 PARETO-DOMINANCE There is no single optimal solution , BUT: some solutions (red dots) are better than all others (gray dots). These solutions are exactly those that are not dominated by any others. They form the so- called non-dominated (Pareto) front .",
    "start": 0,
    "end": 363,
    "length": 363,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.81,
      "keywords": [
        "better",
        "pareto",
        "solutions",
        "dots",
        "others",
        "dominated",
        "1000",
        "1500",
        "2000",
        "2500"
      ]
    }
  },
  {
    "id": "p503_c0",
    "page": 503,
    "text": "MULTI-OBJECTIVE OPTIMIZATION MULTI-OBJECTIVE OPTIMIZATION (MOO) VS MULTI-CRITERIA DECISION MAKING (MCDM) Multi-objective optimization problems (MOPs) are usually solved in two steps: 1. Find the “good” solutions, i. e.",
    "start": 0,
    "end": 219,
    "length": 219,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 6.09,
      "keywords": [
        "multi",
        "objective",
        "optimization",
        "criteria",
        "decision",
        "making",
        "mcdm",
        "problems",
        "mops",
        "usually"
      ]
    }
  },
  {
    "id": "p504_c0",
    "page": 504,
    "text": "500 1000 1500 2000 2500 3000 3500 cost water supply 5 10 15 20 MULTI-OBJECTIVE OPTIMIZATION MULTI-OBJECTIVE OPTIMIZATION (MOO) VS MULTI-CRITERIA DECISION MAKING (MCDM) Multi-objective optimization problems (MOPs) are usually solved in two steps: 2.",
    "start": 0,
    "end": 249,
    "length": 249,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 6.24,
      "keywords": [
        "multi",
        "objective",
        "optimization",
        "1000",
        "1500",
        "2000",
        "2500",
        "3000",
        "3500",
        "cost"
      ]
    }
  },
  {
    "id": "p505_c0",
    "page": 505,
    "text": "MULTI-OBJECTIVE OPTIMIZATION WHEN TO MAKE A DECISION The main difference between “a priori” methods (scalarization, lexicographic method) and “a posteriori” methods (based on Pareto dominance) is when decisions about a problem are made: before or after optimization. 86 After Optimization: search for a set of (Pareto - optimal) solutions select one solution considering constraints, etc. Before Optimization: rank objectives, define constraints,...",
    "start": 0,
    "end": 450,
    "length": 450,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 2.245,
      "keywords": [
        "optimization",
        "when",
        "methods",
        "pareto",
        "before",
        "after",
        "constraints",
        "multi",
        "objective",
        "make"
      ]
    }
  },
  {
    "id": "p506_c0",
    "page": 506,
    "text": "MULTI-OBJECTIVE OPTIMIZATION 87 NON-DOMINATED SORTING GENETIC ALGORITHM-II (NSGA-2 or NSGA-II) • Originally proposed by Deb et al. in 2002, it represents a milestone in multi-objective optimization. y 2 y 1 • Main features – Typically used for binary or real-valued representations – The genetic operators (mutation and crossover) are essentially the same used for single-objective optimization – The selection mechanism (with elitism ) is composed of two parts: 1) Pareto rank based on non-dominated sorting , to select the non-dominated solutions according to their dominance levels 2) crowding-distance sorting to prefer “isolated” solutions to better represent the Pareto front → acts also as a diversity preservation mechanism • Applied widely and successfully, but like other multi- objective evolutionary algorithms its performance breaks down as the number of objectives increases (curse of dimensionality!",
    "start": 0,
    "end": 915,
    "length": 915,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 9.57,
      "keywords": [
        "objective",
        "multi",
        "optimization",
        "dominated",
        "sorting",
        "genetic",
        "nsga",
        "used",
        "mechanism",
        "pareto"
      ]
    }
  },
  {
    "id": "p507_c0",
    "page": 507,
    "text": "WHAT WE HAVE SEEN SO FAR APPLIES TO... 88 NONLINEAR PROGRAMMING • The most general optimization problem occurs when both the objective function and constraints are nonlinear/non-convex, a case referred to as nonlinear programming (NLP). • No speci fi c methods for this class of problems: in practice, one often falls back on metaheuristics (e. g. , Simulated Annealing, Evolutionary Algorithms, etc. ) • To get an exact solution, “backtracking” search methods can be used, which recursively divide up the space into regions can be used. These are applicable if it is possible to compute informative “optimistic” bounds on the best solution within a region, e. g. , by linear approximations.",
    "start": 0,
    "end": 692,
    "length": 692,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.455,
      "keywords": [
        "nonlinear",
        "programming",
        "methods",
        "solution",
        "used",
        "what",
        "have",
        "seen",
        "applies",
        "most"
      ]
    }
  },
  {
    "id": "p508_c0",
    "page": 508,
    "text": "OPTIMIZATION 89 SPECIAL CLASSES OF OPTIMIZATION PROBLEMS Name Vars Constraints Objective Constraint Programming (CP) discrete any N/A Linear Programming (LP) real linear inequalities linear function Integer (Linear) Programming (IP/ILP) integer linear inequalities linear function Mixed Integer (linear) Programming (MIP/MILP) integer & real linear inequalities linear function Semide fi nite Programming (SDP) real linear inequalities + semide fi niteness linear function Quadratic Programming (QP) real linear inequalities quadratic function Quadratically Constrained Quadratic Programming (QCQP) real quadratic inequalities quadratic function Convex Programming real convex region convex function Nonlinear Programming (NLP) real any any",
    "start": 0,
    "end": 741,
    "length": 741,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.7,
      "keywords": [
        "linear",
        "programming",
        "real",
        "function",
        "inequalities",
        "quadratic",
        "integer",
        "convex",
        "optimization",
        "semide"
      ]
    }
  },
  {
    "id": "p510_c0",
    "page": 510,
    "text": "LINEAR PROGRAMMING 91 EXAMPLE: MANUFACTURING A large factory makes tables and chairs. Each table returns a pro fi t of 200 EUR and each chair a pro fi t of 100 EUR. Each table takes 1 unit of metal and 3 units of wood and each chair takes 2 units of metal and 1 unit of wood. The factory has 600 units of metal and 900 units of wood. How many tables and chairs should the factory make to maximize pro fi t?",
    "start": 0,
    "end": 407,
    "length": 407,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 2.03,
      "keywords": [
        "each",
        "units",
        "factory",
        "metal",
        "wood",
        "tables",
        "chairs",
        "table",
        "chair",
        "takes"
      ]
    }
  },
  {
    "id": "p512_c0",
    "page": 512,
    "text": "LINEAR PROGRAMMING 93 WHY “LINEAR PROGRAMMING”? Linear : the objective functions and constraints are linear. Programming : does not refer to computer programming but rather “planning” - planning of activities to obtain an optimal result i. e. , it reaches the speci fi ed goal in the best possible way (according to the given mathematical model) among all feasible alternatives.",
    "start": 0,
    "end": 379,
    "length": 379,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": true,
      "importance": 1.89,
      "keywords": [
        "linear",
        "programming",
        "planning",
        "objective",
        "functions",
        "constraints",
        "does",
        "refer",
        "computer",
        "rather"
      ]
    }
  },
  {
    "id": "p513_c0",
    "page": 513,
    "text": "LINEAR PROGRAMMING 94 SIMPLEX ALGORITHM Basic idea of the simplex algorithm is to move along the edges of the polytope from corner to corner, in directions of decreasing cost. In worst case, move along an exponentially large number of corners, but typically much better in practice (the fi rst “practical” algorithm for linear programming). Guaranteed to fi nd a globally optimal solution (ignoring some possible degenerate cases): if simplex returns, then it has found a point that cannot be further improved locally; since linear programs are convex , this is a global optimum. Since there are a fi nite (but exponential) number of vertices in the polytope, the algorithm must return after a fi nite number of steps, improving at each iteration.",
    "start": 0,
    "end": 748,
    "length": 748,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.735,
      "keywords": [
        "algorithm",
        "linear",
        "simplex",
        "number",
        "programming",
        "move",
        "along",
        "polytope",
        "corner",
        "since"
      ]
    }
  },
  {
    "id": "p514_c0",
    "page": 514,
    "text": "LINEAR PROGRAMMING 95 ALTERNATIVES TO SIMPLEX Interior point methods (they scale better than simplex)",
    "start": 0,
    "end": 102,
    "length": 102,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 0.505,
      "keywords": [
        "simplex",
        "linear",
        "programming",
        "alternatives",
        "interior",
        "point",
        "methods",
        "they",
        "scale",
        "better"
      ]
    }
  },
  {
    "id": "p515_c0",
    "page": 515,
    "text": "LINEAR PROGRAMMING 96 MANY PROBLEMS AND APPLICATIONS CAN BE TACKLED BY LP • Min-cut / max- fl ow network problems • Resource allocation problems • Cost-bene fi t trade-off problems • Distribution network problems • Economic portfolio optimization • Robotic control • Scheduling generation • ... and much more! Many commercial and open-source solvers available, see https://en. wikipedia. org/wiki/Linear_programming https://docs. scipy. org/doc/scipy/reference/optimize.",
    "start": 0,
    "end": 471,
    "length": 471,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 2.35,
      "keywords": [
        "problems",
        "many",
        "network",
        "https",
        "scipy",
        "linear",
        "programming",
        "applications",
        "tackled",
        "resource"
      ]
    }
  },
  {
    "id": "p517_c0",
    "page": 517,
    "text": "98 EXAMPLE: MANUFACTURING Let’s consider the example seen in the previous lecture, buy adding a constraint of integerness: x 1 and x 2 indicate batches of production that cannot be fractioned, i. e. , x 1 and x 2 are integer values. Recall linear program 6K units of metal and 9K units of wood. How many tables 6 x 1 \u000f[HISLZ\u0010 x 2 \u000fJOHPYZ\u0010 Recall linear program A large factory makes tables and chairs. Each table returns $200 and each chair a profit of $100. Each table takes 1 un 3 units of wood and each chair takes 2 units of metal and 1 The factory has 6 units of metal and 9 units of wood. How and chairs should the factory make to maximize profit?",
    "start": 0,
    "end": 654,
    "length": 654,
    "metadata": {
      "hasDefinition": true,
      "hasFormula": false,
      "hasList": false,
      "hasExample": true,
      "importance": 8.265,
      "keywords": [
        "units",
        "each",
        "metal",
        "wood",
        "factory",
        "example",
        "recall",
        "linear",
        "program",
        "tables"
      ]
    }
  },
  {
    "id": "p518_c0",
    "page": 518,
    "text": "INTEGER (LINEAR) PROGRAMMING 99 CHALLENGES OF INTEGER PROGRAMMING The above example was “easy” in that the rounded solution to the LP happened to also be a solution to the integer program. In general, integer solution can be arbitrarily far from the LP solution: Can be hard to even fi nd a feasible solution that is integer valued, e. g. , imagine the task of fi nding an integer solution to some arbitrary set of linear equations Ax = b.",
    "start": 0,
    "end": 440,
    "length": 440,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": true,
      "hasList": false,
      "hasExample": false,
      "importance": 12.195,
      "keywords": [
        "integer",
        "solution",
        "linear",
        "programming",
        "that",
        "challenges",
        "above",
        "example",
        "easy",
        "rounded"
      ]
    }
  },
  {
    "id": "p520_c0",
    "page": 520,
    "text": "101 INEQUALITY FORM An optimization problem like linear programming, except that variables are required to take on integer values: Not a convex problem , because of integer constraint (set of all integers is not a convex set).",
    "start": 0,
    "end": 227,
    "length": 227,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.13,
      "keywords": [
        "problem",
        "integer",
        "convex",
        "inequality",
        "form",
        "optimization",
        "like",
        "linear",
        "programming",
        "except"
      ]
    }
  },
  {
    "id": "p521_c0",
    "page": 521,
    "text": "102 SOLVING ILP PROBLEMS Naïve solution (exhaustive search): given 2 n possible assignments of all the n variables in x , just try each one, return the solution with minimum objective value out of those that satisfy constraints. In the worst case, we can’t do any better than this, but often it is possible to solve the problem much faster in practice. Key idea: relaxing integer constraints I. e. , consider an alternative LP problem where we relax the constraint x ∈ {0,1} n to be x * ∈ [0,1] n : Key point #1 : if the solution to this LP x * has all integer values, then it is also the solution to the integer program. Key point #2 : the optimal objective for the linear program is lower than that of the corresponding integer program. Both points follow trivially from the fact that {0,1} n ⊂ [0,1] n .",
    "start": 0,
    "end": 807,
    "length": 807,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 4.03,
      "keywords": [
        "solution",
        "integer",
        "that",
        "program",
        "possible",
        "objective",
        "constraints",
        "than",
        "this",
        "problem"
      ]
    }
  },
  {
    "id": "p522_c0",
    "page": 522,
    "text": "103 BRANCH AND BOUND The branch and bound algorithm is a greedy informed search applied using LP relaxation to provide bounds on the search tree. LP relaxation is a quickly-computable approximation which gives us a lower bound on the true solution.",
    "start": 0,
    "end": 249,
    "length": 249,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 1.24,
      "keywords": [
        "bound",
        "branch",
        "search",
        "relaxation",
        "algorithm",
        "greedy",
        "informed",
        "applied",
        "using",
        "provide"
      ]
    }
  },
  {
    "id": "p523_c0",
    "page": 523,
    "text": "104 MANY PROBLEMS AND APPLICATIONS CAN BE TACKLED BY ILP • Path planning with obstacles • Many problems in game theory • Constraint satisfaction problems • (Exact) most likely assignment in graphical models • Scheduling and unit commitment NOTES Extremely well-developed set of commercial solvers are available (free for academic use), e. g. , CPLEX. Gurobi, or LocalSolver. For better ef fi ciency these tools often use proprietary “pre-solve” problem simpli fi cation methods, relaxations based on simplex and other LP solvers, branch and bound, and cutting plane generation methods. Open source notably lags behind in this area, with few exceptions such as SCIP ( http://scip. zib. de/ ).",
    "start": 0,
    "end": 692,
    "length": 692,
    "metadata": {
      "hasDefinition": false,
      "hasFormula": false,
      "hasList": false,
      "hasExample": false,
      "importance": 3.455,
      "keywords": [
        "problems",
        "many",
        "with",
        "solvers",
        "methods",
        "scip",
        "applications",
        "tackled",
        "path",
        "planning"
      ]
    }
  }
]